# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

we want to predict whether a person will respond to marketing campaign or not.
The data set has customer information like marital status,education,job and also a dependent y variable with 0 and 1 flag etc.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

Best performing model was VotingEnsemble which I got from AutoML run.
Accuracy for VotingEnsemble is = 0.91732 while logistic regression Accuracy through Hyperdrive is = 0.9096611026808296


## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

The data set contains information about a marketing campaign ran by a bank with flag indicating 
	whether customer had responded or not. Data has all the customer details like their education,job,contact,loan inforrmation,
	also we have information related to date they were contacted like month,weekday etc.
	Below are the list of variable available in the data:-
														job
														marital
														default
														housing
														loan
														contact
														education
														month
														day_of_week
														poutcome
														y
	Data cleaning and pre-processing steps:-
		- I have converted all categoroical column into dummy encode variable 1 and 0.
		- months and day_of_week variable has benn converted into lebel encode variable whith numeric encoding
		  for all the value of month and weekday.
		- Dependent variable 'y' has been converted into 0 and 1 from 'yes' and 'no'.
		- Splited the data into train and test with 70/30 ratio.
   Algorithm and Hyperparameter tuning:-
        - To train our classifier I have used logistic regression algorithm from sklearn package.
		- To tune the hyperparameter of my logistic regression classifier, I have used Hyperdrive from Azure SDK
		- I have tuned two hyperparameter using hyperdrive for my logistic regression, which are
					i) 'C' = which is used for regularization
				   ii) maximum iteration
   Evaluation metric:-
        - To evaluate our classifier performance and select the best classifier I have use 'Accuracy' as my 
		  evaluation metric.


**What are the benefits of the parameter sampler you chose?**

I have choosed Randomsampler. The main benefits of random sample is that it choses parameter from 
all parameter grid randomly and takes very less time to tune and in most of the case it gives accuracy similar to 
grid search whih very less time. 

**What are the benefits of the early stopping policy you chose?**
Early Stopping Policy:-
     - Stopping Policy name - 'Bandit policy'
		  I have used bandit policy to implement early stoping while tuning the hyperparameters.
		  It is based on slack factor/slack amount and evaluation interval.It terminates runs where the
		  primary metric is not within the specified slack factor/slack amount compared to the best performing run.
		- It improves computational efficiency by terminate poorly performing runs instead of running till we finish the
		  all hyperparameter search space and early stoping also helps in avoid overfitting in ML models.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

AutoML gave best model as VotingEnsemble. which is a ensemble model.
As its a tree based ensemble model its hyperparameters which I got from AutoML is min_samples_leaf,
min_samples_split,n_estimators.
n_estimator tells us that how may tree we need to build.
min_samples_split is for like how many sample is needed to make a split . Below are the all values of each hyperparameters

ensembled_algorithm =['XGBoostClassifier','LightGBM','SGD','SGD','SGD','SGD','ExtremeRandomTree']
   Parameters:-
			   min_samples_leaf=0.01,                    
			   min_samples_split=0.15052631578947367,
			   min_weight_fraction_leaf=0.0,
			   n_estimators=10,
			   n_jobs=1,
			   oob_score=True,
			   random_state=None,
			   verbose=0,
			   warm_start=False
			   
			   weights=[0.26666666666666666,
						0.26666666666666666,
						0.2,
						0.06666666666666667,
						0.06666666666666667,
						0.06666666666666667,
						0.06666666666666667]

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
AutoML model which is VotingEnsemble gave accuracy = 0.91732 and our Logistic regression tuned with Hyperdrive gave accuracy=0.9096611,
So its clear that AutoML has better accuracy.
In my openion AutoML accuracy is better because it tries all algorithms on the data the come up with the best performing model.


## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

In future work we can try different model in Hyperdrive also to see their performance also we can explore neural network model also.
In AutoMl we can try using 'enable_stack_ensemble' approach also to see the improvement.

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**


