# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

we want to predict whether a person will respond to marketing campaign or not.
The data set has customer information like marital status,education,job and also a dependent y variable with 0 and 1 flag etc.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

Best performing model was VotingEnsemble which I got from AutoML run.
Accuracy for VotingEnsemble is = 0.91732 while logistic regression Accuracy through Hyperdrive is = 0.9096611026808296


## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

I have used data provided and splited that into train test first using SKLearn train_test_split function into 70/30 ratio.
I used Hyperdrive to tune the hyperparameter for logistic regression classifier.
I have tuned two important hyperparameter one is for regularization which is 'C' and other i used is maximum iteration.


**What are the benefits of the parameter sampler you chose?**

I have choosed Randomsampler. The main benefits of random sample is that it choses parameter from 
all parameter grid randomly and takes very less time to tune and in most of the case it gives accuracy similar to 
grid search whih very less time. 

**What are the benefits of the early stopping policy you chose?**

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

AutoML gave best model as VotingEnsemble. which is a ensemble model.
As its a tree based ensemble model its hyperparameters which I got from AutoML is min_samples_leaf,
min_samples_split,n_estimators.
n_estimator tells us that how may tree we need to build.
min_samples_split is for like how many sample is needed to make a split .

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
AutoML model which is VotingEnsemble gave accuracy = 0.91732 and our Logistic regression tuned with Hyperdrive gave accuracy=0.9096611,
So its clear that AutoML has better accuracy.
In my openion AutoML accuracy is better because it tries all algorithms on the data the come up with the best performing model.


## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

In future work we can try different model in Hyperdrive also to see their performance also we can explore neural network model also.

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**


